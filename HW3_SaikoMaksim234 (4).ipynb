{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0n3Dkvs8Bkz"
      },
      "source": [
        "benchmark_1.csv\n",
        "48.267\n",
        "\n",
        "benckmark_2.csv\n",
        "52.759\n",
        "\n",
        "Public score: 89.656\n",
        "\n",
        "Private score: 86.008"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T13gH5bdoF_F",
        "outputId": "84156246-0776-4321-ec1a-35c2076f1e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install catboost -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_ambGRxEqVm",
        "outputId": "fe913929-dd02-45ab-a8ca-ce05f8d45745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "- competition is now set to: dscs-25-hw3\n"
          ]
        }
      ],
      "source": [
        "!pip -q install --upgrade --force-reinstall --no-deps kaggle > log  # upgrade kaggle package (to avoid a warning)\n",
        "!mkdir -p ~/.kaggle                                           # .kaggle folder must contain kaggle.json for kaggle executable to properly authenticate you to Kaggle.com\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json >log  # First, download kaggle.json from kaggle.com (in Account page) and place it in the root of mounted Google Drive\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json > log                   # Alternative location of kaggle.json (without a connection to Google Drive)\n",
        "!chmod 600 ~/.kaggle/kaggle.json                      # give only the owner full read/write access to kaggle.json\n",
        "!kaggle config set -n competition -v  dscs-25-hw3       # set the competition context for the next few kaggle API calls. !kaggle config view - shows current settings\n",
        "!kaggle competitions download >> log                          # download competition dataset as a zip file\n",
        "!unzip -o *.zip >> log                                        # Kaggle dataset is copied as a single file and needs to be unzipped.\n",
        "lb =!kaggle competitions leaderboard --show                   # print public leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjF8tXwbE0VQ",
        "outputId": "7e305786-363d-4e7e-d2ff-3014ec475dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 310 ms, sys: 18.3 ms, total: 328 ms\n",
            "Wall time: 538 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "%%capture\n",
        "%reset -f\n",
        "from IPython.core.interactiveshell import InteractiveShell as IS; IS.ast_node_interactivity = \"all\"\n",
        "import numpy as np, pandas as pd, time, warnings\n",
        "from collections import defaultdict, deque\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class Timer():\n",
        "    def __init__(self, lim=60):\n",
        "        self.t0, self.lim = time.time(), lim\n",
        "        print(f'⏳ started. You have {lim} sec. Good luck!')\n",
        "    def ShowTime(self):\n",
        "        elapsed = time.time() - self.t0\n",
        "        msg = f'Runtime is {elapsed:.0f} sec'\n",
        "        if elapsed > self.lim:\n",
        "            print(f'\\033[91m\\033[1m{msg} > {self.lim} sec limit!!!\\033[0m')\n",
        "        else:\n",
        "            print(msg)\n",
        "\n",
        "np.set_printoptions(linewidth=100, precision=2, suppress=True)\n",
        "pd.set_option('display.max_columns', 20, 'display.precision', 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj0w0T2wRQ77",
        "outputId": "5bed1c53-f0d4-40dc-f41c-a35f02c44034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ started. You have 120 sec. Good luck!\n"
          ]
        }
      ],
      "source": [
        "tmr = Timer(120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "aOXvmr3PnyX8"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "8al7cVG6DfQ9"
      },
      "outputs": [],
      "source": [
        "def smape(y_true, y_pred):\n",
        "    y_true = np.array(y_true, dtype=float)\n",
        "    y_pred = np.array(y_pred, dtype=float)\n",
        "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    diff = np.abs(y_true - y_pred) / denom\n",
        "    diff[denom == 0] = 0.0\n",
        "    return 100 * np.mean(diff)\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "sample_sub = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "train[\"period_start_dt\"] = pd.to_datetime(train[\"period_start_dt\"])\n",
        "try:\n",
        "    test[\"period_start_dt\"] = pd.to_datetime(test[\"period_start_dt\"])\n",
        "except:\n",
        "    test[\"period_start_dt\"] = pd.to_datetime(test[\"period_start_dt\"], format=\"%d.%m.%Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "uNODCT3IDrX6"
      },
      "outputs": [],
      "source": [
        "for df in [train, test]:\n",
        "    df[\"year\"] = df[\"period_start_dt\"].dt.year\n",
        "    df[\"month\"] = df[\"period_start_dt\"].dt.month\n",
        "    df[\"weekofyear\"] = df[\"period_start_dt\"].dt.isocalendar().week.astype(int)\n",
        "    df[\"quarter\"] = df[\"period_start_dt\"].dt.quarter\n",
        "    df[\"dayofyear\"] = df[\"period_start_dt\"].dt.dayofyear\n",
        "    df[\"dow\"] = df[\"period_start_dt\"].dt.dayofweek\n",
        "    df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
        "    df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
        "    df[\"week_sin\"] = np.sin(2 * np.pi * df[\"weekofyear\"] / 52)\n",
        "    df[\"week_cos\"] = np.cos(2 * np.pi * df[\"weekofyear\"] / 52)\n",
        "    df[\"doy_sin\"] = np.sin(2 * np.pi * df[\"dayofyear\"] / 365)\n",
        "    df[\"doy_cos\"] = np.cos(2 * np.pi * df[\"dayofyear\"] / 365)\n",
        "    df[\"is_december\"] = (df[\"month\"] == 12).astype(int)\n",
        "    df[\"is_january\"] = (df[\"month\"] == 1).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttoQDWtVNmuO",
        "outputId": "b99ef3ed-7643-4c19-fda3-b642405563d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After aggregations - Train: (35344, 43), Test: (1404, 37)\n"
          ]
        }
      ],
      "source": [
        "global_mean = train['demand'].mean()\n",
        "global_std = train['demand'].std()\n",
        "\n",
        "agg_configs = [\n",
        "    ([\"product_rk\"], \"p\"),\n",
        "    ([\"store_location_rk\"], \"s\"),\n",
        "    ([\"product_rk\", \"store_location_rk\"], \"ps\"),\n",
        "    ([\"product_rk\", \"weekofyear\"], \"pw\"),\n",
        "    ([\"store_location_rk\", \"weekofyear\"], \"sw\"),\n",
        "    ([\"product_rk\", \"month\"], \"pm\"),\n",
        "]\n",
        "\n",
        "for keys, prefix in agg_configs:\n",
        "    agg = train.groupby(keys)['demand'].agg(['mean', 'median', 'std']).reset_index()\n",
        "    agg.columns = keys + [f\"{prefix}_mean\", f\"{prefix}_median\", f\"{prefix}_std\"]\n",
        "    train = train.merge(agg, on=keys, how='left')\n",
        "    test = test.merge(agg, on=keys, how='left')\n",
        "\n",
        "for col in train.columns:\n",
        "    if col.endswith(('_mean', '_median', '_std')):\n",
        "        fill_val = global_mean if not col.endswith('_std') else global_std\n",
        "        train[col] = train[col].fillna(fill_val)\n",
        "        test[col] = test[col].fillna(fill_val)\n",
        "\n",
        "print(f\"After aggregations - Train: {train.shape}, Test: {test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "id": "drGUBludEApP"
      },
      "outputs": [],
      "source": [
        "train = train.sort_values(['product_rk', 'store_location_rk', 'period_start_dt']).reset_index(drop=True)\n",
        "train['demand_raw'] = train['demand']\n",
        "\n",
        "lags = [1, 2, 3, 7, 14, 28]\n",
        "windows = [7, 14, 28]\n",
        "\n",
        "for lag in lags:\n",
        "    train[f'lag_{lag}'] = train.groupby(['product_rk', 'store_location_rk'])['demand_raw'].shift(lag)\n",
        "\n",
        "for w in windows:\n",
        "    train[f'roll_mean_{w}'] = train.groupby(['product_rk', 'store_location_rk'])['demand_raw'].transform(\n",
        "        lambda x: x.shift(1).rolling(w, min_periods=1).mean()\n",
        "    )\n",
        "    train[f'roll_std_{w}'] = train.groupby(['product_rk', 'store_location_rk'])['demand_raw'].transform(\n",
        "        lambda x: x.shift(1).rolling(w, min_periods=1).std().fillna(0)\n",
        "    )\n",
        "\n",
        "for alpha in [0.1, 0.3]:\n",
        "    train[f'ema_{int(alpha*10)}'] = train.groupby(['product_rk', 'store_location_rk'])['demand_raw'].transform(\n",
        "        lambda x: x.shift(1).ewm(alpha=alpha).mean()\n",
        "    )\n",
        "\n",
        "train['trend'] = train.groupby(['product_rk', 'store_location_rk']).cumcount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCP1TEHXNcj6",
        "outputId": "8345712f-ce57-41f5-d547-dd607303295b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: 42, Training samples: 35344\n",
            "NaN check - Target: 0, Features: 0\n"
          ]
        }
      ],
      "source": [
        "lag_cols = [f'lag_{l}' for l in lags]\n",
        "roll_cols = [f'roll_mean_{w}' for w in windows] + [f'roll_std_{w}' for w in windows]\n",
        "ema_cols = ['ema_1', 'ema_3']\n",
        "\n",
        "feature_columns = [\n",
        "    'product_rk', 'store_location_rk', 'year', 'month', 'weekofyear', 'quarter',\n",
        "    'month_sin', 'month_cos', 'week_sin', 'week_cos', 'doy_sin', 'doy_cos',\n",
        "    'is_december', 'is_january', 'dow',\n",
        "    'p_mean', 'p_median', 'p_std',\n",
        "    's_mean', 's_median', 's_std',\n",
        "    'ps_mean', 'ps_median', 'ps_std',\n",
        "    'pw_mean', 'sw_mean', 'pm_mean',\n",
        "    'trend'\n",
        "] + lag_cols + roll_cols + ema_cols\n",
        "\n",
        "feature_columns = [f for f in feature_columns if f in train.columns]\n",
        "cat_features = ['product_rk', 'store_location_rk', 'year', 'month', 'weekofyear', 'quarter', 'dow']\n",
        "cat_features = [c for c in cat_features if c in feature_columns]\n",
        "\n",
        "for col in lag_cols + roll_cols + ema_cols:\n",
        "    if col in train.columns:\n",
        "        group_fill = train.groupby(['product_rk', 'store_location_rk'])[col].transform('mean')\n",
        "        train[col] = train[col].fillna(group_fill)\n",
        "        train[col] = train[col].fillna(global_mean)\n",
        "\n",
        "for col in feature_columns:\n",
        "    if col in train.columns:\n",
        "        if train[col].isna().any():\n",
        "            if col in cat_features:\n",
        "                train[col] = train[col].fillna(0).astype(int)\n",
        "            else:\n",
        "                train[col] = train[col].fillna(global_mean)\n",
        "\n",
        "if 'demand_raw' not in train.columns:\n",
        "    train['demand_raw'] = train['demand']\n",
        "train['demand_raw'] = train['demand_raw'].fillna(global_mean)\n",
        "\n",
        "print(f\"Features: {len(feature_columns)}, Training samples: {len(train)}\")\n",
        "print(f\"NaN check - Target: {train['demand_raw'].isna().sum()}, Features: {train[feature_columns].isna().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bSHBWbIEK-f",
        "outputId": "22b0704d-431f-4d4e-c91d-114e36ee2e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 34144, Val size: 1200\n",
            "Train NaNs - Target: 0, Features: 0\n",
            "Val NaNs - Target: 0, Features: 0\n"
          ]
        }
      ],
      "source": [
        "VALID_DAYS = 28\n",
        "max_date = train[\"period_start_dt\"].max()\n",
        "val_start = max_date - pd.Timedelta(days=VALID_DAYS)\n",
        "\n",
        "train_ds = train[train[\"period_start_dt\"] < val_start].reset_index(drop=True)\n",
        "val_ds = train[train[\"period_start_dt\"] >= val_start].reset_index(drop=True)\n",
        "\n",
        "train_ds = train_ds[train_ds['demand_raw'].notna()].reset_index(drop=True)\n",
        "val_ds = val_ds[val_ds['demand_raw'].notna()].reset_index(drop=True)\n",
        "\n",
        "for col in feature_columns:\n",
        "    if col in train_ds.columns:\n",
        "        train_ds[col] = train_ds[col].fillna(global_mean)\n",
        "    if col in val_ds.columns:\n",
        "        val_ds[col] = val_ds[col].fillna(global_mean)\n",
        "\n",
        "print(f\"Train size: {len(train_ds)}, Val size: {len(val_ds)}\")\n",
        "print(f\"Train NaNs - Target: {train_ds['demand_raw'].isna().sum()}, Features: {train_ds[feature_columns].isna().sum().sum()}\")\n",
        "print(f\"Val NaNs - Target: {val_ds['demand_raw'].isna().sum()}, Features: {val_ds[feature_columns].isna().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y8sdE5zWWVg",
        "outputId": "bb535a0b-2077-4b7e-a0f1-0b57e59311f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostRegressor at 0x7d8f4f4870e0>"
            ]
          },
          "metadata": {},
          "execution_count": 226
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MAE: 11.4318\n",
            "Validation SMAPE: 77.6268\n"
          ]
        }
      ],
      "source": [
        "model = CatBoostRegressor(\n",
        "    loss_function='MAE',\n",
        "    iterations=2000,\n",
        "    learning_rate=0.02,\n",
        "    depth=9,\n",
        "    l2_leaf_reg=4,\n",
        "    random_strength=1.2,\n",
        "    bootstrap_type='Bayesian',\n",
        "    bagging_temperature=1.0,\n",
        "    random_seed=42,\n",
        "    early_stopping_rounds=100,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_ds[feature_columns],\n",
        "    train_ds['demand_raw'],\n",
        "    eval_set=(val_ds[feature_columns], val_ds['demand_raw']),\n",
        "    cat_features=cat_features,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "val_pred = model.predict(val_ds[feature_columns])\n",
        "print(f\"Validation MAE: {mean_absolute_error(val_ds['demand_raw'], val_pred):.4f}\")\n",
        "print(f\"Validation SMAPE: {smape(val_ds['demand_raw'], val_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrSVpdpsENnb",
        "outputId": "7e33d35f-f5b7-41ad-bc54-3b2346a74502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized 245 time series queues\n"
          ]
        }
      ],
      "source": [
        "max_history = max(lags + windows + [56])\n",
        "\n",
        "queues = defaultdict(lambda: deque(maxlen=max_history))\n",
        "for (p, s), grp in train.sort_values(\"period_start_dt\").groupby(['product_rk', 'store_location_rk']):\n",
        "    vals = list(grp['demand_raw'].tail(max_history))\n",
        "    q = deque(maxlen=max_history)\n",
        "    for v in vals:\n",
        "        q.append(float(v))\n",
        "    queues[(p, s)] = q\n",
        "\n",
        "group_means = train.groupby(['product_rk', 'store_location_rk'])['demand_raw'].mean().to_dict()\n",
        "prod_means = train.groupby('product_rk')['demand_raw'].mean().to_dict()\n",
        "\n",
        "print(f\"Initialized {len(queues)} time series queues\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "Eo3SZ8zQEQXP"
      },
      "outputs": [],
      "source": [
        "def build_features_from_queue(p, s, row, queues, group_means, prod_means, global_mean):\n",
        "    q = queues.get((p, s), deque([], maxlen=max_history))\n",
        "    arr = list(q)\n",
        "\n",
        "    fallback = group_means.get((p, s), prod_means.get(p, global_mean))\n",
        "\n",
        "    feat = {}\n",
        "\n",
        "    for lag in lags:\n",
        "        if len(arr) >= lag:\n",
        "            feat[f'lag_{lag}'] = arr[-lag]\n",
        "        else:\n",
        "            feat[f'lag_{lag}'] = fallback\n",
        "\n",
        "    for w in windows:\n",
        "        take = arr[-w:] if len(arr) >= 1 else []\n",
        "        feat[f'roll_mean_{w}'] = np.mean(take) if len(take) else fallback\n",
        "        feat[f'roll_std_{w}'] = np.std(take, ddof=0) if len(take) > 1 else 0.0\n",
        "\n",
        "    feat['ema_1'] = arr[-1] if len(arr) else fallback\n",
        "\n",
        "    feat['trend'] = len(arr)\n",
        "\n",
        "    return feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShxL-FJ8WxPU",
        "outputId": "3eeb2103-29bf-4761-b363-e8155288cec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 1404 predictions\n"
          ]
        }
      ],
      "source": [
        "test = test.sort_values('period_start_dt').reset_index(drop=True)\n",
        "test['forecast'] = np.nan\n",
        "unique_dates = sorted(test['period_start_dt'].unique())\n",
        "\n",
        "for current_date in unique_dates:\n",
        "    mask = test['period_start_dt'] == current_date\n",
        "    batch = test[mask].copy()\n",
        "\n",
        "    if batch.shape[0] == 0:\n",
        "        continue\n",
        "\n",
        "    X_rows = []\n",
        "    idxs = []\n",
        "\n",
        "    for idx, row in batch.iterrows():\n",
        "        p = row['product_rk']\n",
        "        s = row['store_location_rk']\n",
        "\n",
        "        feat = build_features_from_queue(p, s, row, queues, group_means, prod_means, global_mean)\n",
        "\n",
        "        for f in feature_columns:\n",
        "            if f not in feat:\n",
        "                feat[f] = row.get(f, global_mean if 'mean' in f else 0)\n",
        "\n",
        "        X_rows.append(feat)\n",
        "        idxs.append(idx)\n",
        "\n",
        "    X_df = pd.DataFrame(X_rows)[feature_columns]\n",
        "\n",
        "    for c in cat_features:\n",
        "        if c in X_df.columns:\n",
        "            X_df[c] = X_df[c].astype(int)\n",
        "\n",
        "    preds = model.predict(X_df)\n",
        "\n",
        "    for i, pval in zip(idxs, preds):\n",
        "        pval = max(0, pval)\n",
        "        test.loc[i, 'forecast'] = pval\n",
        "        key = (test.loc[i, 'product_rk'], test.loc[i, 'store_location_rk'])\n",
        "        queues[key].append(float(pval))\n",
        "\n",
        "print(f\"Generated {test['forecast'].notna().sum()} predictions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stcsUrpuETI8",
        "outputId": "36df4cc3-c190-454d-9fb6-d442e5df1cd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created!\n",
            "Predictions range: [3, 37]\n",
            "Mean prediction: 11.47\n",
            "100% 9.57k/9.57k [00:00<00:00, 16.1kB/s]\n",
            "Successfully submitted to DSCS_25_HW3"
          ]
        }
      ],
      "source": [
        "test['forecast'] = test['forecast'].fillna(global_mean).clip(lower=0)\n",
        "test['forecast'] = np.round(test['forecast']).astype(int)\n",
        "\n",
        "submission = sample_sub.copy()\n",
        "submission = submission.merge(test[['id', 'forecast']], on='id', how='left')\n",
        "submission['predicted'] = submission['forecast'].fillna(int(round(global_mean))).astype(int)\n",
        "submission[['id', 'predicted']].to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Submission file created!\")\n",
        "print(f\"Predictions range: [{submission['predicted'].min()}, {submission['predicted'].max()}]\")\n",
        "print(f\"Mean prediction: {submission['predicted'].mean():.2f}\")\n",
        "\n",
        "!kaggle competitions submit -c dscs-25-hw3 -f submission.csv -m \"Message\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n-Rkw-vRN3k",
        "outputId": "8cca79dc-b9a0-4eb5-d43d-b6fddbdd67dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime is 43 sec\n"
          ]
        }
      ],
      "source": [
        "tmr.ShowTime()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}